{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f991aaf9-5b79-4361-9058-00ed8a464187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "20479\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", 'r',encoding=\"utf-8\") as f:\n",
    "    raw_data=f.read()\n",
    "print(raw_data[:99])\n",
    "print(len(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115bf9e4-6956-482b-ac26-69dc77760e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a990736c-e3ec-4212-a446-1ae606c1868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "preprocess=re.split(r'([,.:;?_!\"()\\']|\\s|--)',raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b67cbd2b-f1b2-46ea-b8d8-66be17ea56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '--', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ', 'great', ' ', 'surprise', ' ', 'to', ' ', 'me', ' ', 'to', ' ', 'hear', ' ', 'that', ',', '', ' ', 'in', ' ', 'the', ' ', 'height', ' ', 'of', ' ', 'his', ' ', 'glory', ',', '', ' ', 'he', ' ', 'had', ' ', 'dropped', ' ', 'his', ' ', 'painting', ',', '', ' ', 'married', ' ', 'a', ' ', 'rich', ' ', 'widow', ',', '', ' ', 'and', ' ', 'established', ' ', 'himself', ' ', 'in', ' ', 'a', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(preprocess[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74d31d9d-d5ca-4e44-9127-f3887ff54fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "preprocessed=[item.strip() for item in preprocess if item.strip()]\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2d38500-bedb-4e84-8499-0a2cba3bfcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';', '?', 'A', 'Ah', 'Among', 'And', 'Are', 'Arrt', 'As', 'At', 'Be', 'Begin', 'Burlington', 'But', 'By', 'Carlo', 'Chicago', 'Claude', 'Come', 'Croft', 'Destroyed']\n"
     ]
    }
   ],
   "source": [
    "new=sorted(set(preprocessed))\n",
    "print(new[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61485dd8-ba72-44da-807d-5a0011e24c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab={token:integer for integer,token in enumerate(new)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a569608-3acb-4564-beb4-3a1301c0e815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(vocab.items()):\n",
    "    if i<50:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "94e17036-aec6-4f2e-aae1-816b390c1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_tokenizer:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int=vocab\n",
    "        self.int_to_str={i:s for s,i in vocab.items()}\n",
    "    def encoder(self,text):\n",
    "        preprocessed=re.split(r'([,.:;?_!\"()\\']|\\s|--)',text)\n",
    "        preprocessed=[item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    def decoder(self,ids):\n",
    "        result=\" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1',result)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c2421e97-8ca3-4b42-a041-4c653a246c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"The height of his glory\"--that was what the women called it.\"\"\"\n",
    "tokenizer=simple_tokenizer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "03f194d5-621d-4df9-94ac-ceed38a500f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"It's the last he painted, you know,\"\"\"\n",
    "        \n",
    "ids = tokenizer.encoder(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cccdb4a5-8049-48d2-9cbb-44e067d2fac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It' s the last he painted, you know,\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decoder(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2dbf8080-f998-41a9-b39f-7379a947a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens=sorted(set(new))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab={token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bfa37cf6-36f9-4b3e-ac75-6a91efd1ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2faf7d-4fc1-49e9-bd07-c24d92b4e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_tokenizer:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int=vocab\n",
    "        self.int_to_str={i:s for s,i in vocab.items())\n",
    "    def encoder(self,text):\n",
    "         preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "         preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        preprocessed=[item if item in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fcc5da-6baa-45f2-9fa3-33ed7cf45bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\eedim\\anaconda3\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\eedim\\anaconda3\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eedim\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eedim\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eedim\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eedim\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/893.9 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/893.9 kB 325.1 kB/s eta 0:00:03\n",
      "   ---- ---------------------------------- 92.2/893.9 kB 751.6 kB/s eta 0:00:02\n",
      "   ----- -------------------------------- 122.9/893.9 kB 722.1 kB/s eta 0:00:02\n",
      "   ------- ------------------------------ 174.1/893.9 kB 871.5 kB/s eta 0:00:01\n",
      "   -------- ----------------------------- 194.6/893.9 kB 841.6 kB/s eta 0:00:01\n",
      "   --------- ---------------------------- 225.3/893.9 kB 724.0 kB/s eta 0:00:01\n",
      "   ---------- --------------------------- 256.0/893.9 kB 749.3 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 286.7/893.9 kB 737.3 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 389.1/893.9 kB 897.8 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 450.6/893.9 kB 909.8 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 532.5/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 604.2/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 686.1/893.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 686.1/893.9 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 716.8/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 716.8/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ---- 778.2/893.9 kB 963.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 849.9/893.9 kB 994.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 893.9/893.9 kB 991.8 kB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57f326-f0ea-4384-8d31-85aa6849fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Byte pair Encoding \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385ec1d4-4042-48b9-a45c-a9556cea530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.0\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import importlib\n",
    "print(importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee6b19-ddcf-4975-9d67-c1d4bba959df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "486c564c-780b-46d0-af34-37399d8a47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Hello world !!!!!\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "063ef5af-bf37-4c2b-92f2-b6e6c9a34554",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54816063-efb8-42af-ae3b-64038ac7611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d06b60e3-5188-466f-97ce-d47ffd9a0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder=tokenizer.decode(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f6bb8eb-4546-4ff1-ba67-ff3b86e6643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d4ebb57-f99a-465d-92b0-ea7d2b7d2343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n",
      "dfgdfg dfg kk sy\n"
     ]
    }
   ],
   "source": [
    "text=(\"dfgdfg dfg kk sy\")\n",
    "integer= tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)\n",
    "decoder=tokenizer.decode(integer)\n",
    "print(decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0f905e6-1322-4278-aaca-121989a56240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2-->50257\n",
      "gpt3-->50281\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoder={\"gpt2\":tiktoken.get_encoding(\"gpt2\"),\"gpt3\":tiktoken.get_encoding(\"p50k_base\")}\n",
    "vocab_size={model:encoding.n_vocab for model,encoding in encoder.items()}\n",
    "for model,vocab in vocab_size.items():\n",
    "    print(f'{model}-->{vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa507041-6fa7-4305-849f-e617231766de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24-03-2025 today i have learnt about torch , n_vocab which is build method to find the sizze of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396af0a-40b4-40b3-82fe-ee2de8e1f1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da0817-f57f-46b7-b5e0-95f9818e7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f3e636e-ee9f-40bf-99af-479994939c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n===========================================\\n             CREATE INPUT TARGET PAIRS\\n===========================================\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "===========================================\n",
    "             CREATE INPUT TARGET PAIRS\n",
    "===========================================\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15f8db8f-c2bd-4e55-9e17-5c59feffaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016, 257, 922, 5891, 1576, 438, 568, 340, 373, 645, 1049, 5975, 284, 502, 284, 3285, 326, 11, 287, 262, 6001, 286, 465, 13476, 11, 339, 550, 5710, 465, 12036, 11, 6405, 257, 5527, 27075, 11]\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\",'r',encoding=\"utf-8\") as f:\n",
    "    raw_text=f.read()\n",
    "encoder=tokenizer.encode(raw_text)\n",
    "print(encoder[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0031c693-eed4-4d66-84c6-019c22813f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aab8452a-9aa0-4d8b-872a-4b28aab5201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=encoder[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53f9e1e4-202a-4922-b86a-485a224e909d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [40, 367, 2885, 1464]\n",
      "y:     [367, 2885, 1464, 1807]\n"
     ]
    }
   ],
   "source": [
    "#creating context_size\n",
    "context_size =4\n",
    "x=sample[:4]\n",
    "y=sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:     {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "613ecc9b-5243-48f6-b4f8-d059dbfbe065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] ---> 367\n",
      "[40, 367] ---> 2885\n",
      "[40, 367, 2885] ---> 1464\n",
      "[40, 367, 2885, 1464] ---> 1807\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context=sample[:i] \n",
    "    desired=sample[i]\n",
    "    print(context, \"--->\" ,desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6c2a664-a72c-4555-b8e1-86499da5a7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --->  H\n",
      "I H ---> AD\n",
      "I HAD --->  always\n",
      "I HAD always --->  thought\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context=sample[:i]\n",
    "    desired=sample[i]\n",
    "    print(tokenizer.decode(context), \"--->\" ,tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc9cf690-97b1-4c25-8d7a-f197de06a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "894a83b6-a833-4654-8aa6-9c516a578ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c08c17b6-3387-443e-b486-e415225a2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1904ad47-2ad6-4f46-9fbb-01bdc87141a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cpu\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f55483a-a0bb-465d-9ea9-48bbf5d8019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea969f55-a1cc-463e-a576-38299c11b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087c9d40-78ec-4098-80e2-951662d93ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example let us consider we have a sentense that contain 6 word, each word is token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a22f26e-6316-4689-bb09-7c0aff8bc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence-->\"quick fox is in the house\"  and the vocabulary id of the sentence is [4,0,3,2,5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f81eeb14-842d-47b1-bd31-299fea391dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we are trying to create a embedding layers it is also called as look up table ,and is is 2d array (vector dim,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "965520d0-7cd5-4726-a3f1-c9ad65962613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs= torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e125a34d-53bb-49e1-9c7d-5bb93a9bb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dim=3\n",
    "vocab_size=6\n",
    "embedding=torch.nn.Embedding(vocab_size,out_dim) # it will create a embedding layers and the table will contain 6 rows,3 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "30b01376-1317-4e43-91bd-ee700526d77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(embedding.weight.shape) \n",
    "emb=embedding(inputs)\n",
    "print(emb.shape)#weights will return the weight which are assigned randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6beeaddb-b771-47ee-9d0c-ef6b4adf812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get each vocab id values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec68f19c-ee57-463a-ba51-83b05d0b6455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3705,  0.9944, -0.4975], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding.weight[3])\n",
    "# the output of this is the fourth row in the matrics, and these embedding weights are further optimised ass the part of LLM traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "99d24fb3-9ec4-4e63-a030-8c9c3e0dc3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#postional embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9d9a4ecf-527b-48da-88d9-aaa9a1e5b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is last step in the preprocessing the data to fed in to llm ,intially we assign random value to the tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2551b031-3890-4f3f-8f4a-cacf98d6dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 2 types of postional embeddings actual and relational,actual is used when there is fixed size sequence\n",
    "#finalembedding values=positional embedding+input embedding value,which can store the postion information also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b104cd60-3675-49ea-915c-39750a09523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab= 50256\n",
    "out_dim=256\n",
    "embedding_layers=torch.nn.Embedding(vocab,out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4690baf1-8d07-45ca-8f1b-75e59932abcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6050,  0.1398, -0.0721,  ..., -0.6158,  0.3069,  0.8245],\n",
      "        [-1.5410, -0.9663, -1.8412,  ...,  0.5697, -1.0209, -0.3935],\n",
      "        [ 1.2595, -0.0836, -1.3133,  ..., -0.9393, -1.9312,  0.7490],\n",
      "        ...,\n",
      "        [-0.3781,  0.0614,  2.3069,  ..., -0.4582, -0.0806, -0.6688],\n",
      "        [ 0.4665, -0.7378, -0.5742,  ..., -1.1120, -1.1221, -0.9053],\n",
      "        [ 0.3817, -0.5956, -0.8147,  ..., -1.1816, -1.3363,  1.9665]],\n",
      "       requires_grad=True)\n",
      "torch.Size([50256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layers.weight)\n",
    "print(embedding_layers.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191fec8-8051-43b4-8413-8f9dc89cc806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a8f89989-49f2-479b-a03d-bb5be9f09306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   11,  6405,   257,  5527],\n",
      "        [ 3436,    11,   290,  1645],\n",
      "        [  262,  6473,   438,  5562],\n",
      "        [  938,   475,   530,   553],\n",
      "        [  588,   683,   438,  8807],\n",
      "        [   11, 12704,   257,  1310],\n",
      "        [ 2215,   262,   530,  1517],\n",
      "        [ 1359,   290,   965,  1397]])\n"
     ]
    }
   ],
   "source": [
    "max_len=4\n",
    "dataloder=create_dataloader_v1(raw_data, batch_size=8, max_length=max_len, \n",
    "                         stride=max_len)\n",
    "data =iter(dataloder)\n",
    "inputs,target=next(data)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "248f581b-f64f-4311-a89d-db3c6ecd4676",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9b0c93f0-d8e2-497e-9fea-866f7255862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6405,   257,  5527, 27075],\n",
      "        [   11,   290,  1645,  1752],\n",
      "        [ 6473,   438,  5562,   314],\n",
      "        [  475,   530,   553,   673],\n",
      "        [  683,   438,  8807,   314],\n",
      "        [12704,   257,  1310,  2952],\n",
      "        [  262,   530,  1517,   326],\n",
      "        [  290,   965,  1397,    11]])\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4370834b-0107-40c2-8608-b3254ca2174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=embedding_layers(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e30ca431-670f-4cd0-aa88-d439218af7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a4263e41-3ea8-49e0-90c6-edd3a8fa0ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "positional_embedding=torch.nn.Embedding(max_len,out_dim)\n",
    "print(positional_embedding.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2746f55d-ad1a-4d2c-b53f-b0924465f7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8220e+00,  8.6425e-01, -1.8508e-01, -1.0823e+00,  1.6627e-01,\n",
      "        -4.1529e-01,  1.0453e+00, -9.0473e-02,  4.6338e-01, -1.9372e-01,\n",
      "        -1.4759e+00, -9.6808e-01,  1.0758e+00, -1.0225e+00,  7.6635e-01,\n",
      "        -1.7472e+00, -9.7972e-01,  4.2885e-01,  2.6151e+00,  2.2810e-01,\n",
      "         1.3635e+00, -6.5099e-02,  2.8649e-01,  3.1370e-01, -4.0296e-01,\n",
      "         9.7504e-02, -4.3693e-01, -9.4205e-01, -7.0550e-01,  7.6422e-02,\n",
      "         1.2984e+00,  1.4404e-02,  7.3587e-01, -1.1252e+00,  6.6131e-01,\n",
      "        -1.9933e-01, -3.0482e-01, -1.3131e+00,  4.6865e-01, -1.4626e-01,\n",
      "         1.1872e-01,  3.8299e-01, -7.6120e-01, -1.6018e+00,  2.0062e-01,\n",
      "        -9.0893e-02, -9.8629e-02, -4.0145e-01, -8.0305e-01, -1.0757e+00,\n",
      "         1.2520e+00,  5.6389e-01, -1.3878e-01,  1.9541e+00,  1.5287e+00,\n",
      "        -8.5846e-01, -1.0039e+00,  1.9675e+00, -1.1889e+00,  3.5575e-01,\n",
      "        -2.1741e+00, -8.2599e-01,  9.2608e-01, -4.1156e-01,  4.5936e-01,\n",
      "         3.1565e-01, -1.4682e-01, -3.0241e-01, -5.7271e-01, -1.8215e+00,\n",
      "         8.7508e-02,  6.7697e-01,  9.5715e-01,  8.1686e-01,  1.1807e-01,\n",
      "         9.5695e-02, -1.0376e+00, -1.2332e+00, -5.5764e-01, -8.7843e-02,\n",
      "         6.2887e-01, -1.8161e+00,  1.4774e+00, -3.7289e-01, -7.6618e-02,\n",
      "        -6.3926e-02,  6.7239e-01,  1.1001e+00, -6.9282e-01,  9.7415e-01,\n",
      "         9.7914e-01,  8.4383e-01, -4.4536e-01, -3.8910e-02,  1.6520e+00,\n",
      "        -4.6939e-01, -1.1926e+00,  7.5073e-01, -5.4256e-01,  6.5630e-01,\n",
      "         9.9452e-01,  2.6102e-03, -4.4752e-03, -1.5329e+00,  4.6287e-01,\n",
      "        -5.1488e-01,  1.2050e+00,  4.1876e-01, -1.2713e+00, -3.5488e-01,\n",
      "         4.4873e-01,  3.3494e-01,  9.6705e-01, -1.7289e+00,  2.1625e+00,\n",
      "        -5.2716e-01, -4.2299e-01, -3.6715e-01,  1.0930e+00, -8.2866e-01,\n",
      "        -3.4533e-01, -3.9328e-01, -3.9531e-03, -1.0169e+00,  4.1705e-01,\n",
      "        -4.6506e-01, -8.6056e-01, -1.0304e+00,  5.9323e-01, -9.4210e-01,\n",
      "         1.4488e-01, -5.8716e-01,  4.6266e-01,  6.9646e-01,  1.7925e+00,\n",
      "         1.1738e+00, -2.8423e-01, -5.4181e-02, -4.6544e-01, -2.9422e-01,\n",
      "        -5.1351e-01,  9.5175e-01, -2.3406e-01, -6.2083e-01,  1.7753e+00,\n",
      "         6.2828e-01,  2.5590e-02,  1.2361e+00, -1.0254e+00, -1.3037e+00,\n",
      "         2.3477e-01,  1.1384e+00,  4.5224e-01,  1.7610e+00, -2.6943e-01,\n",
      "        -2.0137e-02, -1.1356e+00,  9.8478e-01, -1.3639e+00,  4.5572e-01,\n",
      "         1.0211e+00, -5.1367e-01,  1.0885e+00, -5.5800e-02,  3.3878e-01,\n",
      "        -6.7537e-01,  1.2095e+00,  2.0067e-01,  6.1571e-02, -7.5092e-01,\n",
      "         1.1027e+00,  4.3372e-01, -2.3243e+00,  1.3863e-01, -1.3985e+00,\n",
      "         9.5568e-01, -8.4784e-01, -1.2483e+00, -1.3800e+00,  2.0850e-01,\n",
      "        -7.6605e-01, -3.9402e-01,  3.6768e-01,  6.0221e-01, -6.3529e-01,\n",
      "         2.3995e-01,  1.2159e+00, -2.3807e+00, -7.9422e-01, -2.9015e-01,\n",
      "         2.0480e+00, -8.9243e-01, -8.0011e-01,  2.8004e+00, -4.8428e-01,\n",
      "         1.4392e+00, -1.9633e+00,  1.1731e+00, -8.0000e-01,  7.4372e-01,\n",
      "        -9.9480e-01, -8.9929e-01,  5.1189e-01, -1.3512e+00, -2.0078e+00,\n",
      "         9.9740e-01, -3.5939e-01,  4.8042e-01,  3.7638e-01, -9.4782e-01,\n",
      "        -1.8236e+00,  6.5410e-01,  1.4003e-01,  2.4203e+00, -3.3698e-01,\n",
      "        -1.2474e+00,  5.2651e-02, -2.1157e+00,  3.1747e-01,  4.5250e-01,\n",
      "         1.6023e-01,  3.8365e-01, -1.9978e-01, -1.0256e+00, -1.0919e-01,\n",
      "         5.5654e-01, -1.6673e-01,  1.4758e+00, -6.2026e-01, -1.0195e+00,\n",
      "         7.8641e-01,  5.5957e-01,  1.0409e-01,  1.9336e+00,  9.9668e-01,\n",
      "         3.6382e-01,  8.8399e-01,  5.4046e-01, -2.3237e-01, -2.7949e-01,\n",
      "        -1.0154e+00, -1.1429e+00,  1.8213e-01,  1.8511e+00,  3.9552e-01,\n",
      "         1.3498e+00,  2.0415e-01, -1.4224e+00,  1.3493e+00, -5.9772e-01,\n",
      "         2.3357e+00,  8.8088e-01,  1.3429e+00,  3.5102e-01,  1.5558e+00,\n",
      "         1.6376e+00], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.1660,  0.9884, -1.2124,  0.2207, -0.9480,  0.5234, -0.2269,  0.4497,\n",
      "         1.1145, -0.3236, -0.5569,  0.0157, -2.2687, -1.9181, -0.1837, -0.2445,\n",
      "        -1.0312, -1.1290,  1.3433, -0.8321, -1.0876, -0.0068,  0.7947, -0.4044,\n",
      "        -0.7085, -0.0115,  1.2355,  1.3065,  0.9408,  1.5057, -0.8693, -0.8928,\n",
      "         0.7030, -0.0967,  0.0778,  0.3920,  0.0974,  0.1357,  0.3673, -0.8219,\n",
      "         0.6195,  1.1903,  1.2827, -0.3699, -0.4960,  0.8498, -0.2770,  0.9730,\n",
      "        -1.7868,  0.3007, -0.4952, -0.4368, -0.6748,  0.2709, -0.1266,  0.3218,\n",
      "        -0.5721, -2.2050, -1.1963,  0.5987,  2.3160,  1.2454, -0.4918, -0.2486,\n",
      "         1.8178, -0.2663,  0.7206, -1.8948, -0.3876,  1.2606,  0.1468, -1.2495,\n",
      "        -0.7750, -1.3239, -1.2776, -1.6404, -0.3463,  0.4849,  0.4101,  1.3655,\n",
      "         0.4059,  0.5499, -0.6202, -1.8869,  0.6009,  0.9044,  0.7001,  0.1813,\n",
      "        -0.1473,  0.7291,  1.1401, -1.0378,  0.4542,  0.2984,  0.4803, -0.1213,\n",
      "        -1.0942, -0.6995,  0.7821,  1.7445, -0.7204, -0.8151,  1.5170, -0.1083,\n",
      "        -0.8154,  0.3223,  1.0910,  0.2483,  0.2951, -0.2971, -0.1944,  0.1346,\n",
      "         0.2613, -0.5619,  1.0097, -1.3574, -0.7575, -1.5055, -0.3843,  0.1426,\n",
      "        -0.1787, -0.8884,  0.6102, -2.2468,  0.1474,  0.2970,  1.1473,  0.6136,\n",
      "         1.1548, -0.7347,  1.1796, -0.0954, -0.3028, -0.5599,  0.1943,  0.2335,\n",
      "         0.5489,  0.7534,  1.5562, -0.7271, -0.8204,  1.0262, -0.8764, -0.9276,\n",
      "        -0.6143,  0.5304,  0.4308, -1.2061, -0.0532,  0.7173, -0.5826,  1.6627,\n",
      "        -1.1699, -0.4574, -1.5179,  0.4238, -0.4602, -0.4434,  0.2081,  1.6841,\n",
      "        -0.0028,  1.2379,  0.9187, -0.0169,  1.7974, -0.8027, -0.9078,  0.4976,\n",
      "         0.1712, -0.5812, -0.8975,  0.0326, -0.6318, -1.4387,  0.5386,  1.6165,\n",
      "        -0.5488,  0.1919,  0.4052,  0.7895, -1.3662, -1.5746,  0.4410,  0.1794,\n",
      "         0.5120,  0.8830,  0.1700,  0.7599,  0.3540, -0.8358, -0.2838, -0.6057,\n",
      "         0.7296, -0.8609,  1.2136,  0.4397, -0.6680, -1.3312, -0.1001, -1.5763,\n",
      "        -0.3501, -0.3820,  0.9417, -1.0128, -0.3667,  0.3778, -0.2087,  0.0981,\n",
      "         0.9739,  1.7925,  0.2684, -1.3193,  0.6639,  0.4575,  1.3865,  0.8627,\n",
      "        -0.0416, -1.0643,  1.1433, -1.1281, -1.0097,  1.1409,  0.6951, -0.4223,\n",
      "         0.5942,  0.3674,  2.3318, -0.6239,  1.6721,  0.8598,  1.7770, -1.2306,\n",
      "         1.4310,  0.2777,  0.5767,  1.3059, -0.5322, -0.1254, -0.4186,  0.2093,\n",
      "         2.3414,  1.4988, -0.9147,  0.1206,  1.5161,  1.3901, -1.0495,  0.8709,\n",
      "         1.8866, -0.9082,  0.7323, -0.5336, -0.0239,  1.8487,  0.3088, -1.5793],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings_layer = positional_embedding(torch.arange(max_len))\n",
    "print(pos_embeddings_layer[1])\n",
    "print(pos_embeddings_layer[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5904f-41be-438f-bbf8-61ce8c501f4a",
   "metadata": {},
   "source": [
    "### final_embeddings=embeddings+pos_embeddings_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2857ce84-12a1-44fa-a62c-2e5036b2c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.9988, -0.5149,  0.7897,  ..., -0.2232,  1.3689, -0.4255],\n",
      "         [-2.0955,  1.0882, -0.1274,  ..., -0.3236,  1.4284,  0.8635],\n",
      "         [-0.1366,  0.7911, -1.0750,  ...,  4.5298, -0.5612, -1.4319],\n",
      "         [ 0.1610,  3.2377, -1.9857,  ..., -0.1351,  1.1687,  0.0733]],\n",
      "\n",
      "        [[ 0.4882, -1.2724,  0.3640,  ...,  0.3591,  1.6726, -0.5937],\n",
      "         [-1.1446,  0.5286,  0.4174,  ...,  1.3894,  1.5488,  0.5062],\n",
      "         [-1.5095,  0.7531, -0.8817,  ...,  1.3828, -0.9507, -1.3376],\n",
      "         [-1.4237,  1.4147, -4.2738,  ...,  1.0002,  0.7777,  2.2051]],\n",
      "\n",
      "        [[ 1.7267,  2.3527, -0.3981,  ..., -0.7703,  2.0535, -0.4336],\n",
      "         [-2.1615,  1.5871, -0.7354,  ..., -0.2248,  1.9919,  1.6214],\n",
      "         [ 0.9534,  1.6284, -2.1856,  ...,  2.9086, -0.2398, -2.3083],\n",
      "         [-0.3370,  0.3713, -3.9851,  ..., -1.9749,  2.5017,  0.4478]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.9988, -0.5149,  0.7897,  ..., -0.2232,  1.3689, -0.4255],\n",
      "         [-1.8379, -1.5482, -1.5281,  ...,  0.2909,  2.4792,  1.3078],\n",
      "         [-0.1366,  0.7911, -1.0750,  ...,  4.5298, -0.5612, -1.4319],\n",
      "         [-0.1954,  0.8164, -1.2047,  ...,  0.0906,  0.4059,  0.2777]],\n",
      "\n",
      "        [[ 0.0225,  0.3270, -0.9848,  ...,  0.7200,  3.5991,  1.6504],\n",
      "         [-1.4168,  3.3961, -0.7704,  ...,  0.8423,  2.2334,  0.4981],\n",
      "         [ 0.1342,  1.9710, -2.2559,  ...,  1.1118, -0.5468, -0.0855],\n",
      "         [-2.9612,  0.6665, -3.3875,  ..., -1.1537,  0.6959, -0.5434]],\n",
      "\n",
      "        [[ 1.1060,  0.8128, -0.0564,  ..., -2.1566,  1.7639,  0.9042],\n",
      "         [-3.1655,  0.6290,  0.1455,  ..., -0.1148,  0.2963,  1.8793],\n",
      "         [-0.5740,  1.1482, -1.5507,  ...,  1.0354,  2.8381, -0.6261],\n",
      "         [-1.0383,  2.2605, -3.2323,  ..., -0.0229, -0.2763, -0.1405]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79603ce-5f1b-4411-9e4a-00d62ab3acaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
